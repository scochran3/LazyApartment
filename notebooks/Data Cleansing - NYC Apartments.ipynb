{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "These notebook will explore our raw data after the AWS Lambda data pipeline. The final output of that pipeline is a large amount of JSON data files dumped to S3 with data coming from Craigslist, Mapquest and WalkScore.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Our Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ce6f44e948d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get Credentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_credentials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maws_secret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aws'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aws_secret_access_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maws_access_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aws'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aws_access_key_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "# Get Credentials\n",
    "credentials = Config.read_credentials()\n",
    "aws_secret = credentials['aws']['aws_secret_access_key']\n",
    "aws_access_key = credentials['aws']['aws_access_key_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the raw JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys of files\n",
    "s3 = boto3.client('s3',\n",
    "                 aws_access_key_id=aws_access_key,\n",
    "                 aws_secret_access_key=aws_secret)\n",
    "\n",
    "bucket = 'lazyapartment'\n",
    "objects = s3.list_objects_v2(Bucket='lazyapartment', Prefix='walkScoreEnhancedData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all the raw JSON to Pandas for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all of the keys into a list\n",
    "keys = [obj['Key'] for obj in objects['Contents']][1:]\n",
    "\n",
    "# Put all the raw data into a pandas dataframe\n",
    "data = []\n",
    "s3 = boto3.resource('s3')\n",
    "for key in keys:\n",
    "    bucket_object = s3.Object(bucket, key)\n",
    "    contents = bucket_object.get()['Body'].read().decode('utf-8')\n",
    "    json_data = json.loads(contents)\n",
    "\n",
    "    for apartments in json_data:\n",
    "        data.append(apartments)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Lower all string features\n",
    "df['name'] = df['name'].str.lower()\n",
    "df['where'] = df['where'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the DF for easy access later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Export for easy access later\n",
    "# df = df.set_index('id')\n",
    "# df = df.to_csv('housing.csv')\n",
    "df = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "### Separate out latitude and longtidue, drop Geotag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = df['geotag'].apply(lambda x: x[1:x.index(',')])\n",
    "df['lon'] = df['geotag'].apply(lambda x: x[x.rindex(',')+1:-1])\n",
    "df.drop(columns='geotag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up area\n",
    "Unfortunately many of the apartment listings don't have an area in square feet included. For those that do have square footage they come in as strings, so here we remove \"ft2\" from the column and convert it to a numeric datatype. We can also make a feature for whether or not the posting includes the square footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUpArea(row):\n",
    "    if type(row) == str:\n",
    "        row = int(row.replace('ft2', ''))\n",
    "    else:\n",
    "        row\n",
    "    return row\n",
    "\n",
    "df['area'] = df['area'].apply(lambda x: cleanUpArea(x))\n",
    "df['includes_area'] = df['area'].apply(lambda x: 0 if np.isnan(x) else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up Price\n",
    "Similarly price is a string as it is prefixed with a '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].apply(lambda x: x.replace('$', '')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "Convert the datetime field to a datetime and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M')\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['dow'] = df['datetime'].dt.dayofweek\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['hour'] = df['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Bedrooms\n",
    "For whatever reason Craigslist always labels Studios to have 1 bedroom, or often it is missing. For now we will lazily fill apartments that have the word studio in the title with 0 bedrooms or otherwise use the value provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "def parseBedrooms(row):\n",
    "    if any(re.findall(r'studio', row['name'], re.IGNORECASE)):\n",
    "        return 0\n",
    "    if np.isnan(row['bedrooms']):\n",
    "        if any(re.findall(r'1br|1bedroom|1bd|1 bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 1\n",
    "        elif any(re.findall(r'1br|1bedroom|1bd|1 bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 2\n",
    "        elif any(re.findall(r'1br|1bedroom|1bd|1 bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 3\n",
    "    else:\n",
    "        return row['bedrooms']\n",
    "\n",
    "df['bedrooms'] = df.apply(parseBedrooms, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Fee\n",
    "Many apartments in New York have an additional fee (realtors) attached. Let's create a feature that is whether or not \"No Fee\" is advertised in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['advertises_no_fee'] = df['name'].apply(lambda x: 1 if 'no fee' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repost\n",
    "Many apartments are reposted on Craigslist if they are not sold as this will put them back at the top of the list for people to see who sort by \"Newest to Oldest\". Let's create a feature for if this is a report or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_repost'] = df['repost_of'].apply(lambda x: 1 if not np.isnan(x) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert booleans to 1/0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_image'] = df['has_image'].astype(int)\n",
    "df['has_map'] = df['has_map'].astype(int)\n",
    "df['sideOfStreetEncoded'] = df['sideOfStreet'].map({'L':0, 'R':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode location\n",
    "We can one hot encode the postal code as this will play nicer with our algorithm of choice later. We will use a chopped version of the postal codes to prevent our matrix from becoming too sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postalCodeChopped'] = df['postalCode'].astype(str).apply(lambda x: x[0:x.index('-')] if '-' in x else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Price Outliers\n",
    "There are a couple of apartments that are way out there for prices (it is NYC after all). This is an exploration for the common man, so let's remove absurdly expensive apartments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_std = df['price'].std()\n",
    "df = df[df['price'] < (df['price'].mean() + 3*price_std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "Now that the data is cleaned (somewhat) we can start exploring the relationship among the different features and our response of price. This is done in the Data Exploration - NYC Apartments notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')\n",
    "df.to_csv('housing_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
