{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "These notebook will explore our raw data after the AWS Lambda data pipeline. The final output of that pipeline is a large amount of JSON data files dumped to S3 with data coming from Craigslist, Mapquest and WalkScore.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Our Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import Config\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Credentials\n",
    "credentials = Config.read_credentials()\n",
    "aws_secret = credentials['aws']['aws_secret_access_key']\n",
    "aws_access_key = credentials['aws']['aws_access_key_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the raw JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys of files\n",
    "s3 = boto3.client('s3',\n",
    "                 aws_access_key_id=aws_access_key,\n",
    "                 aws_secret_access_key=aws_secret)\n",
    "\n",
    "bucket = 'lazyapartment'\n",
    "objects = s3.list_objects_v2(Bucket='lazyapartment', Prefix='walkScoreEnhancedData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all the raw JSON to Pandas for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all of the keys into a list\n",
    "keys = [obj['Key'] for obj in objects['Contents']][1:]\n",
    "\n",
    "# Put all the raw data into a pandas dataframe\n",
    "data = []\n",
    "s3 = boto3.resource('s3')\n",
    "for key in keys:\n",
    "    bucket_object = s3.Object(bucket, key)\n",
    "    contents = bucket_object.get()['Body'].read().decode('utf-8')\n",
    "    json_data = json.loads(contents)\n",
    "\n",
    "    for apartments in json_data:\n",
    "        data.append(apartments)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Lower all string features\n",
    "df['name'] = df['name'].str.lower()\n",
    "df['where'] = df['where'].str.lower()\n",
    "\n",
    "# Export for easy access later\n",
    "df = df.set_index('id')\n",
    "df = df.to_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the DF for easy access later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "### Separate out latitude and longtidue, drop Geotag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = df['geotag'].apply(lambda x: x[1:x.index(',')])\n",
    "df['lon'] = df['geotag'].apply(lambda x: x[x.rindex(',')+1:-1])\n",
    "df.drop(columns='geotag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up area\n",
    "Unfortunately many of the apartment listings don't have an area in square feet included. For those that do have square footage they come in as strings, so here we remove \"ft2\" from the column and convert it to a numeric datatype. We can also make a feature for whether or not the posting includes the square footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n",
    "def cleanUpArea(row):\n",
    "    if type(row) == str:\n",
    "        row = int(row.replace('ft2', ''))\n",
    "    else:\n",
    "        row\n",
    "    return row\n",
    "\n",
    "df['area'] = df['area'].apply(lambda x: cleanUpArea(x))\n",
    "df['includes_area'] = df['area'].apply(lambda x: 0 if np.isnan(x) else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up Price\n",
    "Similarly price is a string as it is prefixed with a '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].apply(lambda x: x.replace('$', '')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "Convert the datetime field to a datetime and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M')\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['dow'] = df['datetime'].dt.dayofweek\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['hour'] = df['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Bedrooms\n",
    "For now we will hackily parse for information about the bedrooms that don't include the information. Eventually this seems to be a not very difficult NLP problem to solve once enough data is acquired. I say not very difficult as a 2 bedroom apartment is often, in text, described with either \"2BR\", \"2BD\" or \"2 Bedroom\" which should be easy enough to solve with NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseBedrooms(row):\n",
    "    if np.isnan(row['bedrooms']):\n",
    "        if any(re.findall(r'studio', row['name'], re.IGNORECASE)):\n",
    "            return 0\n",
    "        elif any(re.findall(r'1BD|1 BD|1BR|1 BR|1 bedroom|1bedroom|one bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 1\n",
    "        elif any(re.findall(r'2BD|2 BD|2BR|2 BR|2 bedroom|2bedroom|two bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 2\n",
    "        elif any(re.findall(r'3BD|3 BD|3BR|3 BR|3 bedroom|3bedroom|three bedroom', row['name'], re.IGNORECASE)):\n",
    "            return 3\n",
    "    else:\n",
    "        return row['bedrooms']\n",
    "\n",
    "df['bedrooms_filled'] = df.apply(parseBedrooms, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Fee\n",
    "Many apartments in New York have an additional fee (realtors) attached. Let's create a feature that is whether or not \"No Fee\" is advertised in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['advertises_no_fee'] = df['name'].apply(lambda x: 1 if 'no fee' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert booleans to 1/0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_image'] = df['has_image'].astype(int)\n",
    "df['has_map'] = df['has_map'].astype(int)\n",
    "df['sideOfStreetEncoded'] = df['sideOfStreet'].map({'L':0, 'R':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode location\n",
    "We can one hot encode the postal code as this will play nicer with our algorithm of choice later. We will use a chopped version of the postal codes to prevent our matrix from becoming too sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postalCodeChopped'] = df['postalCode'].apply(lambda x: x[0:x.index('-')] if '-' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['postalCodeChopped'], prefix='postal')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "Now that the data is cleaned (somewhat) we can start exploring the relationship among the different features and our response of price. This is done in the Data Exploration - NYC Apartments notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
